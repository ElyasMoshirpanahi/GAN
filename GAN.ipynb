{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run on google colab:     <a href=\"https://colab.research.google.com/github/elyas1376/GAN/blob/main/GAN.ipynb\" target=\"_blank\" rel=\"noreferrer noopener\"><img src=\"https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667\" alt=\"Open In Colab\" data-canonical-src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"max-width: 100%;\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "cellView": "form",
        "id": "VoMbmMZaAvtl"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision import transforms as trfms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "import sys\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "cellView": "form",
        "id": "5GnXr6ekSX7a"
      },
      "outputs": [],
      "source": [
        "#@title Creating Transformer to transform train img data\n",
        "transformers  = trfms.Compose([\n",
        "    trfms.ToTensor(),\n",
        "    trfms.Normalize(0.5,0.5)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "cellView": "form",
        "id": "h8HBHLucUyau"
      },
      "outputs": [],
      "source": [
        "#@title Downloading dataset and createing dataloader\n",
        "dataset =  FashionMNIST(\"./\",train = True, transform = transformers,download= True)\n",
        "\n",
        "batch_size = 128\n",
        "dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True,num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "L5KLkbr8TJ5v"
      },
      "outputs": [],
      "source": [
        "#@title random tensor to IMG\n",
        "t = torch.randn((104,3,28,28))\n",
        "save_image(t,\"test.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "cellView": "form",
        "id": "CPwUN42BVo-9"
      },
      "outputs": [],
      "source": [
        "#@title Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator,self).__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,stride=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(in_features=(32*24*24), out_features=256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(in_features=256, out_features=32),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(in_features=32, out_features=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv(x)\n",
        "    x = x.view(-1,32*24*24)\n",
        "    x = self.fc(x)\n",
        "    return x \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "d = Discriminator()\n",
        "t = torch.randn((20,1,28,28))\n",
        "img = d.forward(t)\n",
        "save_image(img,\"dis_test.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "cellView": "form",
        "id": "UavKmF8NEJx5"
      },
      "outputs": [],
      "source": [
        "#@title Generator\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self,latent_dim):\n",
        "    super(Generator,self).__init__()\n",
        "\n",
        "\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "\n",
        "    self.fully_connected = nn.Sequential(\n",
        "        nn.Linear(in_features = self.latent_dim , out_features=1280),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.BatchNorm1d(num_features=1280, momentum=0.7),\n",
        "\n",
        "        nn.Linear(in_features = 1280 , out_features=2560),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.BatchNorm1d(num_features=2560, momentum=0.7),\n",
        "        \n",
        "        \n",
        "        nn.Linear(in_features = 2560 , out_features=5760),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.BatchNorm1d(num_features=5760, momentum=0.7),# 10 * 24 *24\n",
        "    )\n",
        "\n",
        "\n",
        "    self.conv_transpose = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels = 10, out_channels=3,kernel_size=3,stride = 1),#  3 *26*26\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.ConvTranspose2d(in_channels = 3, out_channels=1,kernel_size=3,stride = 1),\n",
        "        nn.Tanh())\n",
        "    \n",
        "\n",
        "  def forward(self,x):\n",
        "    x= self.fully_connected(x)\n",
        "    x = x.view(-1,10,24,24)\n",
        "    x = self.conv_transpose(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "test = torch.randn(5,64)\n",
        "g = Generator(64)\n",
        "img = g.forward(test)\n",
        "save_image(img,f\"gen_test.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "cellView": "form",
        "id": "NbsK-pGLJhac"
      },
      "outputs": [],
      "source": [
        "#@title Parameters\n",
        "\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "\n",
        "latent_dim = 64\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "\n",
        "### creating models\n",
        "D = Discriminator().to(device)\n",
        "G = Generator(latent_dim).to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4lJMKMfVoqD",
        "outputId": "51ea4c49-0bd4-4475-b0a4-09b6733bdbdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch: 13/300] ,[Batch 469/469] , [d_loss: 0.32488], [g_loss:1.36108] [ETA : 0:00:23.441186/1:57:12.355800]"
          ]
        }
      ],
      "source": [
        "#@title Train Loop\n",
        "ones_ = torch.ones(batch_size ,1).to(device)\n",
        "zeros_= torch.zeros(batch_size ,1).to(device)\n",
        "\n",
        "d_losses = []\n",
        "g_losses = []\n",
        "\n",
        "N_EPOCHS = 300\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = dt.now()\n",
        "  for batch_i , (inputs,_) in enumerate(dataloader):\n",
        "    n = inputs.size(0)\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    ones =  ones_[:n] #True  (real) labels\n",
        "    zeros= zeros_[:n] #False (fake) labels\n",
        "    \n",
        "    ##################################\n",
        "    #######Train Discriminator########\n",
        "    ##################################\n",
        "    \n",
        "    #real images\n",
        "    real_outputs = D.forward(inputs)\n",
        "    d_loss_real  = criterion(real_outputs,ones)\n",
        "\n",
        "\n",
        "\n",
        "    #fake images\n",
        "    noise = torch.randn(n,latent_dim).to(device)\n",
        "    fake_images = G.forward(noise)\n",
        "\n",
        "    fake_outputs=D.forward(fake_images)\n",
        "    d_loss_fake = criterion(fake_outputs,zeros)\n",
        "\n",
        "    #Gradient Decient Step\n",
        "    d_loss = 0.5 * (d_loss_fake + d_loss_real)\n",
        "\n",
        "    d_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()\n",
        "\n",
        "    d_loss.backward()\n",
        "\n",
        "    d_optimizer.step()\n",
        "\n",
        "    ##################################\n",
        "    ####### Train Generator ###########\n",
        "    ##################################\n",
        "    \n",
        "    for i in range(2):\n",
        "      #fake images \n",
        "      noise = torch.randn(n,latent_dim).to(device)    \n",
        "      fake_images = G.forward(noise)\n",
        "      fake_outputs = D.forward(fake_images)\n",
        "\n",
        "      g_loss = criterion(fake_outputs,ones)#tricking the discriminator by giving true labels  along with fake outputs\n",
        "\n",
        "      #Zero grading the optimizers\n",
        "      d_optimizer.zero_grad()\n",
        "      g_optimizer.zero_grad()\n",
        "\n",
        "        #Grading the g_loss\n",
        "      g_loss.backward()\n",
        "\n",
        "      #Stepping forward toward the train with the defined learning-rate\n",
        "      g_optimizer.step()\n",
        "\n",
        "    d_losses.append(d_loss.item())\n",
        "    g_losses.append(g_loss.item())\n",
        "\n",
        "  end =  dt.now() - start\n",
        "  info  = \"Epoch: {:3d} , d_loss:{:2.4f}, g_loss:{:2.4f}\".format(epoch,d_loss.item(),g_loss.item())\n",
        "  sys.stdout.write(\n",
        "      \"\\r[Epoch: %d/%d] ,[Batch %d/%d] , [d_loss: %2.5f], [g_loss:%2.5f]\"\n",
        "      %(\n",
        "          epoch,\n",
        "          N_EPOCHS,\n",
        "          batch_i+1,\n",
        "          len(dataloader),\n",
        "          d_loss.item(),\n",
        "          g_loss.item()\n",
        "      )\n",
        "  )\n",
        "  #print(info)\n",
        "\n",
        "  fake_images = (fake_images.reshape(-1,1,28,28) + 1)/2\n",
        "\n",
        "  os.makedirs('Generated Images',exist_ok = True)\n",
        "  save_image(fake_images,'Generated Images/{:03d}.png'.format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4YXhFAhXsIK"
      },
      "outputs": [],
      "source": [
        "#@title Plotting g and d losses\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.plot(d_losses,label = 'd_losses')\n",
        "plt.plot(g_losses,label = 'g_losses')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
